import os, re, sys
import glob
import numpy as np
from datetime import datetime
from matplotlib import pyplot as plt

import src.coarsenSatData


import src.mapByLonLat as mll


maskPointsCloseToTheCoast = True
minDistFromCoast = 20000
minObsForValidation = 0
maskShallowPoints = False
minSeaDepth = -5
bathyFile = "/home/lmentaschi/usr/WaveWatchIII/gridgen1.1/reference_data/etopo2.nc"


def elaborateMeasures(
    startDate,
    endDate,
    hsSatAndModelDir,
    outputDir,
    latlims=[-63, 63],
    lonlims=[-180, 180],
    filterLowHs=False,
    filterHsThreshold=0.0,
    dx=0.2,
    dy=0.2,
    pth = 90, 
):

    years = []


    def iterateByYear():
        fls_ = [f for f in os.listdir(hsSatAndModelDir) if re.match("(.*)\.npy", f)]
        pttrn = "(.*)_hsModelAndSatObs_([0-9]{8}).npy"
        dtstrs = [re.match(pttrn, f).groups(0)[1] for f in fls_]
        dts = [datetime.strptime(dtstr, "%Y%m%d") for dtstr in dtstrs]
        iii = np.argsort(dts)
        dts = np.array(dts)[iii]
        fls_ = np.array(fls_)[iii]
        fls = [
            fls_[i]
            for i in range(len(fls_))
            if (startDate <= dts[i] and endDate >= dts[i])
        ]

        loopYear = None

        def loadFile(flpth):
            print("")
            print("    loading file " + flpth)
            satdts = np.load(flpth)
            if filterLowHs:
                hssat = satdts[:, 3]
                hsmdl = satdts[:, 4]
                cnd = np.logical_and(
                    hssat > filterHsThreshold, hsmdl > filterHsThreshold
                )
                satdts = satdts[cnd, :]
            return satdts

        def _elab_ssh(dts, lons, lats, saths, modhs):
            maplons, maplats, mapdata = mll.mapByLonLat(
                dts, lons, lats, saths, modhs, dx, dy, lonlims=lonlims, latlims=latlims
            )
            return (
                maplons,
                maplats,
                mapdata,
            )

        def _elab(dts, lons, lats, saths, modhs):
            maplons, maplats, mapdata = mll.mapByLonLat(
                dts, lons, lats, saths, modhs, dx, dy, lonlims=lonlims, latlims=latlims
            )
            (
                sqDevSum,
                dtcount,
            ) = mll.computeCumDeviations(maplons, maplats, mapdata)
            obsMax, mdlMax = mll.computeMaxima(maplons, maplats, mapdata)
            return (
                maplons,
                maplats,
                obsSum,
                sqObsSum,
                devSum,
                sqDevSum,
                mdlByObsSum,
                dtcount,
                obsMax,
                mdlMax,
            )

        for f in fls:
            fpth = os.path.join(hsSatAndModelDir, f)
            satdts_ = loadFile(fpth)
            dts = satdts_[:, 0]
            currYr = datetime.fromtimestamp(dts[0]).year
            if loopYear is None:
                loopYear = currYr
                years.append(loopYear)
                satdts = None
                print("  loading year " + str(loopYear))
            if loopYear == currYr:
                satdts = (
                    satdts_ if satdts is None else np.concatenate([satdts, satdts_], 0)
                )
            else:
                # loopYear != currYr
                # yielding the current year
                dts = satdts[:, 0]
                lons = satdts[:, 1]
                lats = satdts[:, 2]
                saths = satdts[:, 3]
                modhs = satdts[:, 4]
                yield _elab_ssh(dts, lons, lats, saths, modhs)
                satdts = satdts_
                loopYear = currYr
                years.append(loopYear)
                print("  loading year " + str(loopYear))

        # yielding the last year
        dts = satdts[:, 0]
        lons = satdts[:, 1]
        lats = satdts[:, 2]
        saths = satdts[:, 3]
        modhs = satdts[:, 4]
        yield _elab_ssh(dts, lons, lats, saths, modhs)

    (
        sqDevSum,
        dtcount,
    ) = (None, None)
    for blob in iterateByYear():
        (
            maplons,
            maplats,
            _sqDevSum,
            _dtcount,
        ) = blob
        if _sqDevSum is None:
            continue
        if sqDevSum is None:
            (
                sqDevSum,
                dtcount,
            ) = (
                _sqDevSum,
                _dtcount,
            )
        else:
            sqDevSum = np.nansum([sqDevSum, _sqDevSum], 0)
            dtcount = np.nansum([dtcount, _dtcount], 0)

    if not latlims is None:
        cnd = np.logical_and(maplats >= latlims[0], maplats <= latlims[1])
        maplats = maplats[cnd]
        sqDevSum = sqDevSum[cnd, :]
        dtcount = dtcount[cnd, :]

    if maskPointsCloseToTheCoast:
        msk = mll.createCoastlinePointsMask(
            maplons, maplats, resl="h", minDistFromCoast=minDistFromCoast
        )
        cnd = msk == 0
        obsSum[cnd] = np.nan
        sqObsSum[cnd] = np.nan
        devSum[cnd] = np.nan
        sqDevSum[cnd] = np.nan
        mdlByObsSum[cnd] = np.nan
        dtcount[cnd] = np.nan
        obsMaxSum[cnd] = np.nan
        mdlMaxSum[cnd] = np.nan
        obsTotMax[cnd] = np.nan
        mdlTotMax[cnd] = np.nan

    if maskShallowPoints:
        msk = mll.createBathyMask(maplons, maplats, minSeaDepth, bathyFile)
        cnd = msk == 0
        obsSum[cnd] = np.nan
        sqObsSum[cnd] = np.nan
        devSum[cnd] = np.nan
        sqDevSum[cnd] = np.nan
        mdlByObsSum[cnd] = np.nan
        dtcount[cnd] = np.nan
        obsMaxSum[cnd] = np.nan
        mdlMaxSum[cnd] = np.nan
        obsTotMax[cnd] = np.nan
        mdlTotMax[cnd] = np.nan

    cnd = dtcount < minObsForValidation
    sqDevSum[cnd] = np.nan
    diff = np.nansum(sqDevSum)
    print(diff)


    # Compute rmse and extract mean from data
    sat_mean, mod_mean = mll.computeMean(maplons, maplats, mapdata)

    deviation_ = np.ones((len(maplats), len(maplons))) * np.nan
    _consideredCells = 0
    data_sat_ = []
    data_sat = []
    data_mod_ = []
    data_mod = []
    for ix in range(len(maplons)):
        for iy in range(len(maplats)):
            data = mp.get((ix, iy))
            if not data:
                continue
            msrs = np.array(data[3])
            data_sat_.append(msrs)
            mods = np.array(data[4])
            data_mod_.append(mods)

            msrs_sum = np.sum(np.array(data[3]))
            mods_sum = np.sum(np.array(data[4]))

            deviation_[iy, ix] = np.sum((mods - msrs) ** 2.0)
#            print(deviation_[iy, ix])
#            print(iy, ix)
            _consideredCells += 1

    deviation = deviation_/(_consideredCells)
    sat_mean = msrs_sum / _consideredCells
    mod_mean = mods_sum / _consideredCells

    print("considered cells: ", _consideredCells)

    # flatting array
    for i in range(len(data_sat_)):
      data_sat.extend(data_sat_[i])
    for i in range(len(data_mod_)):
      data_mod.extend(data_mod_[i])

    #sat_mean = np.nanmean(data_sat)
    #mod_mean = np.nanmean(data_mod)
    print("mean sat data = ", sat_mean)
    print("mean mod data = ", mod_mean)

    data_mod = data_mod - mod_mean
#    data_sat = data_sat - sat_mean

#    sat_meann = np.nanmean(data_sat)
#    print("mean sat data after remove mean = ", sat_meann)

    pth_data_mod = np.nanpercentile(data_mod, pth)
    pth_data_sat = np.nanpercentile(data_sat, pth)
    print("pth sat = " , pth_data_sat)
    print("pth mod = " , pth_data_mod)

    filter_data_sat = []
    filter_data_mod = []

    # compute NSE and Coefficient of determination
    nse1 = 0
    nse2 = 0
    ssres = 0
    sstot = 0
    _consideredCellsFilter = 0
    for ix in range(len(maplons)):
        for iy in range(len(maplats)):
            data = mp.get((ix, iy))
            if not data:
                continue
            msrs = np.array(data[3])
            mods = np.array(data[4])
            for i in range(len(msrs)):
                if msrs[i] >= pth_data_sat and mods[i] >= pth_data_mod:
      #              nse1 += (mods[i] - msrs[i])**2
      #              nse2 += (msrs[i] - sat_mean)**2
      #              ssres += (mods[i] - msrs[i])**2
      #              sstot += (msrs[i] - sat_mean)**2
                    filter_data_sat.append(msrs[i])
                    filter_data_mod.append(mods[i])
                else:
                    continue

    filt_data_sat = np.array(filter_data_sat)
    filt_data_mod = np.array(filter_data_mod)

    print("mean filt_data_sat = ", np.nanmean(filt_data_sat))
    nse1 = np.sum((filt_data_mod - filt_data_sat)**2)
    nse2 = np.sum((filt_data_sat - np.nanmean(filt_data_sat))**2)
    # It is exactly the same, right?
    ssres = np.sum((filt_data_mod - filt_data_sat)**2)
    sstot = np.sum((filt_data_sat - np.nanmean(filt_data_sat))**2)


    print("considered cells after percentile filtering: ", len(filter_data_sat))
    nse = 1 - nse1/nse2
    r2 = 1 - ssres/sstot
    print("NSE = ", nse)
    print("R2 = ", r2)

    #cnd = dtcount < minObsForValidation
    #obsSum[cnd] = np.nan
    #sqObsSum[cnd] = np.nan
    #devSum[cnd] = np.nan
    #sqDevSum[cnd] = np.nan
    #mdlByObsSum[cnd] = np.nan
    #dtcount[cnd] = np.nan
    #obsMaxSum[cnd] = np.nan
    #mdlMaxSum[cnd] = np.nan
    #obsTotMax[cnd] = np.nan
    #mdlTotMax[cnd] = np.nan


    rmseTot = np.sqrt(np.nansum(deviation))
    totIndStr = """
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
TOTAL ERROR INDICATORS:
rmse: {rmseTot:2.5f}
NSE: {nse:2.5f}
R2: {r2:2.5f}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
"""
    totIndStr = totIndStr.format(
        rmseTot=rmseTot,
        nse=nse,
        r2=r2,
    )
    print("")
    print(totIndStr)
    print("")
    totIndsFilePath = os.path.join(outputDir, "totalIndicators.txt")
    with open(totIndsFilePath, "w") as f:
        f.write(totIndStr)
        f.close()

    rmse = np.sqrt(deviation)

    # saving to files
    try:
        os.makedirs(outputDir)
    except:
        pass
    np.savetxt(os.path.join(outputDir, "lons.csv"), maplons)
    np.savetxt(os.path.join(outputDir, "lats.csv"), maplats)
    np.savetxt(os.path.join(outputDir, "rmse.csv"), rmse)

    print("output dir: " + outputDir)
